embeddings:
  model: "law-ai/InLegalBERT"
  dimension: 768
  # IMPORTANT: The python code directly in YAML value won't work.
  # You need to resolve this in your Python code *after* loading the config.
  # Let's set a placeholder or the desired default for now.
  device: "auto" # Or "cuda" or "cpu" as a default string

retrieval:
  chunk_size: 512
  chunk_overlap: 200
  top_k: 5
  index_type: "IndexFlatIP"
  data_dir: "data/processed/faiss"
  nlist: 100
  device: "auto" # Or "cuda" or "cpu" as a default string

generation:
  model: "google/gemma-3-1b-it"
  max_new_tokens: 256
  temperature: 0.7
  device: "auto" # Or "cuda" or "cpu" as a default string

api:
  host: "0.0.0.0"
  port: 8000